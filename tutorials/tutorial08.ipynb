{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE9010: Introduction to Data Science\n",
    "## Semester 2 2017/18\n",
    "## Xavier Bresson\n",
    "<hr>\n",
    "\n",
    "## Tutorial 8: Neural networks\n",
    "## Objectives\n",
    "### $\\bullet$ Coding 3-layer neural network\n",
    "### $\\bullet$ Implementing backpropagation\n",
    "### $\\bullet$ Explore results\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# math library\n",
    "import numpy as np\n",
    "\n",
    "# remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "# computational time\n",
    "import time\n",
    "\n",
    "# import mat data\n",
    "import scipy.io\n",
    "\n",
    "# dynamic 3D rotations:\n",
    "#%matplotlib notebook \n",
    "# no 3D rotations but cleaner images:\n",
    "%matplotlib inline    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 3D visualization\n",
    "import pylab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# high definition picture\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png2x','pdf')\n",
    "\n",
    "# visualize 2D images\n",
    "import scipy.ndimage\n",
    "\n",
    "# import mat data\n",
    "import scipy.io\n",
    "\n",
    "# random number\n",
    "import random\n",
    "\n",
    "# colormap\n",
    "import matplotlib.cm as cm \n",
    "\n",
    "# for one-hot vector\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load training and test datasets\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load('data/nn_train_test_sets.npz')['X_train']\n",
    "y_train = np.load('data/nn_train_test_sets.npz')['y_train']\n",
    "X_test = np.load('data/nn_train_test_sets.npz')['X_test']\n",
    "y_test = np.load('data/nn_train_test_sets.npz')['y_test']\n",
    "\n",
    "print('Nb training data:',X_train.shape[1])\n",
    "print('Nb test data:',X_test.shape[1])\n",
    "print('Nb data features:',X_train.shape[0])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the datasets\n",
    "<hr>\n",
    "\n",
    "Hint: You may use function `display_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_data(X,width,height,nrows,ncols,title):\n",
    "\n",
    "    big_picture = np.zeros((height*nrows,width*ncols))\n",
    "    indices_to_display = random.sample(range(X.shape[1]), nrows*ncols)\n",
    "    irow, icol = 0, 0\n",
    "    for idx in indices_to_display:\n",
    "        if icol == ncols:\n",
    "            irow += 1\n",
    "            icol  = 0       \n",
    "        iimg = X[:,idx].reshape(width,height).T       \n",
    "        big_picture[irow*height:irow*height+iimg.shape[0],icol*width:icol*width+iimg.shape[1]] = iimg\n",
    "        icol += 1\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.title(title)\n",
    "    img = scipy.misc.toimage( big_picture )\n",
    "    plt.imshow(img,cmap = cm.Greys_r)\n",
    "    \n",
    "    \n",
    "#YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Z-score the datasets\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement a 3-layer neural network classifier.\n",
    "<hr>\n",
    "\n",
    "The input layer has $n_1=d=400$ neurons.\n",
    "The hidden layer has $n_2=25$ neurons.\n",
    "The output layer has $n_3=K=10$ neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 10 # number of classes\n",
    "n = X_train.shape[1] # number of training data\n",
    "\n",
    "n1 = 400\n",
    "n2 = 25\n",
    "n3 = K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Function definitions\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot transform function\n",
    "def convert_to_one_hot(X,max_val=None):\n",
    "    N = X.size\n",
    "    data = np.ones(N,dtype=int)\n",
    "    sparse_out = coo_matrix((data,(np.arange(N),X.ravel())), shape=(N,max_val))\n",
    "    return np.array(sparse_out.todense().T)\n",
    "\n",
    "#Example:\n",
    "#a = np.array([1, 7, 5, 3, 2, 4, 0, 4])\n",
    "#print(a)\n",
    "#print(convert_to_one_hot(a,10)) \n",
    "\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(z):\n",
    "    sigmoid_f = 1 / (1 + np.exp(-z)) \n",
    "    return sigmoid_f \n",
    "\n",
    "\n",
    "# derivate of the sigmoid function\n",
    "def sigmoid_derivate(z):\n",
    "    sigm = sigmoid(z)\n",
    "    return sigm* (1-sigm)\n",
    "\n",
    "\n",
    "# accuracy function\n",
    "def compute_acc(y,ygt):\n",
    "    diff = (y == ygt).astype('int')\n",
    "    accuracy = 100* sum(diff)/ y.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Convert the training label vector `y_train`, with values in ${1,2,...,K}$, to one-hot vector.\n",
    "<hr>\n",
    "\n",
    "Hint: You may use function `convert_to_one_hot(y,K)` with `y` having values in ${0,1,...,K-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Initialize the weight matrices $W^1$ and $W^2$ with the formula\n",
    "$$\n",
    "W^l = U\\Big[ -\\frac{2}{\\sqrt{n_l}}, \\frac{2}{\\sqrt{n_l}} \\Big],\n",
    "$$\n",
    "with $U$ being the uniform distribution.\n",
    "<hr>\n",
    "\n",
    "Hint: You may use function `np.random.uniform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Implement the backpropagation algorithm from Lecture 10.\n",
    "<hr>\n",
    "\n",
    "The loss function is the multi-class regression loss. The learning rate is $\\tau=0.2$ and the number of iterations is $5000$. Do not use any regularization at this moment $\\lambda=0$. \n",
    "\n",
    "Note the accuracy of the train set and the test set for $n_2=25$ and $\\lambda=0$.\n",
    "\n",
    "Hint: Implement slide 53 of Lecture 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tau = 0.2 # learning rate\n",
    "lamb = 0  # regularization\n",
    "\n",
    "# iterate\n",
    "for iter in range(5000):\n",
    "    \n",
    "    # forward pass\n",
    "    #YOUR CODE HERE\n",
    "    Y1 = \n",
    "    Y1bias = \n",
    "    Y2 = \n",
    "    Y2bias = \n",
    "    Y3 = \n",
    "    \n",
    "    # backward pass\n",
    "    #YOUR CODE HERE\n",
    "    Delta3 = \n",
    "    Grad2 = \n",
    "    W2 = \n",
    "    W2bar = W2[:,1:n2+1]\n",
    "    Delta2 = \n",
    "    Grad1 = \n",
    "    W1 = \n",
    "    \n",
    "    # print intermediate result\n",
    "    if not iter%500:\n",
    "        \n",
    "        # loss \n",
    "        loss = -1/n* ( np.sum(Yhat* np.log(Y3+1e-10)) + \\\n",
    "                      np.sum((1-Yhat)* np.log((1-Y3)+1e-10)) ) + \\\n",
    "                lamb* ( np.sum(W1) + np.sum(W2) )\n",
    "        \n",
    "        # train accuracy\n",
    "        Y3_classes = np.argmax(Y3,axis=0)\n",
    "        Ygt = np.argmax(Yhat,axis=0)\n",
    "        acc = compute_acc(Y3_classes,Ygt)\n",
    "        \n",
    "        # test accuracy (with forward pass on the test set)\n",
    "        Y1_test = X_test\n",
    "        Y1bias_test = np.insert(Y1_test,0,1,axis=0)\n",
    "        Y2_test = sigmoid(W1.dot(Y1bias_test))\n",
    "        Y2bias_test = np.insert(Y2_test,0,1,axis=0)\n",
    "        Y3_test = sigmoid(W2.dot(Y2bias_test))\n",
    "        Y3_classes_test = np.argmax(Y3_test,axis=0)\n",
    "        Ygt_test = (y_test-1).squeeze()\n",
    "        acc_test = compute_acc(Y3_classes_test,Ygt_test)\n",
    "        \n",
    "        # print\n",
    "        print('iter:',iter,'loss:',loss,'train acc:',acc,'test acc:',acc_test)\n",
    "        \n",
    "    \n",
    "print('iter:',iter+1,'loss:',loss,'train acc:',acc,'test acc:',acc_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Increase the learning capacity of the network by taking $n_2=100$.\n",
    "<hr>\n",
    "\n",
    "Note the accuracy of the train set and the test set for $n_2=100$ and $\\lambda=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "W1_no_regularization = W1 # for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Regularize the network with $\\lambda=0.005$\n",
    "<hr>\n",
    "\n",
    "Note the accuracy of the train set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize the learned features [Bonus]\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1bar = W1_no_regularization[:,1:].T\n",
    "display_data(W1bar,20,20,5,5,'Learned features without regularization')\n",
    "\n",
    "W1bar = W1[:,1:].T\n",
    "display_data(W1bar,20,20,5,5,'Learned features with regularization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
